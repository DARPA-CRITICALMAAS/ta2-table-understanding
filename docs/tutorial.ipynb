{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ca21b6",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is designed to guide you through the key functionalities of the library, providing hands-on examples and explanations.\n",
    "\n",
    "First, we need to import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77cff273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tum.dag import *\n",
    "from tum.config import PROJECT_DIR\n",
    "\n",
    "EXAMPLE_DIR = PROJECT_DIR / \"docs/examples\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc32a38",
   "metadata": {},
   "source": [
    "Choose the example (folder name) you want to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c0d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = EXAMPLE_DIR / \"copper\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b7e7e9",
   "metadata": {},
   "source": [
    "### Defining the DAG for Data Extraction\n",
    "\n",
    "Our data extraction workflow is structured as a *Directed Acyclic Graph* (DAG). Each node in the DAG, referred to as an *actor*, represents a specific step in the process, while the edges define the data flow between these steps. The workflow is composed of four primary steps:\n",
    "\n",
    "1. **(id=table)**: Read and normalize the table.\n",
    "2. **(id=sem_label)**: Predict semantic types.\n",
    "3. **(id=sem_desc)**: Create a semantic description.\n",
    "4. **(id=export)**: Export the data.\n",
    "\n",
    "#### Controlling Workflow Execution\n",
    "\n",
    "To control which steps to execute, set the `output` argument to the desired step's ID. Only the specified step and its ancestor steps will be executed. For example:\n",
    "- To test the table normalization step, set the output to `table`.\n",
    "- Once the table normalization step is verified, set the output to `sem_model` or `export` to run the complete workflow.\n",
    "\n",
    "#### Semantic Model Integration\n",
    "\n",
    "In the `sem_model` step:\n",
    "- The `sem_label` step is used to predict semantic descriptions.\n",
    "- The example is uploaded to SAND for semantic description curation.\n",
    "\n",
    "After curating the semantic description in SAND:\n",
    "- Run the DAG again with the `export` step to export the data.\n",
    "- The `export` step uses the curated semantic description to generate the final output that can be imported to MinMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fcb11b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-01 12:14:48.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlibactor.storage._global_storage\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mGlobalStorage: /Volumes/research/workspace/projects/darpa-criticalmaas/ta2-table-understanding/docs/examples/copper/storage\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dag: 0.016 seconds\n"
     ]
    }
   ],
   "source": [
    "dag = get_dag(\n",
    "    cwd,\n",
    "    # pipeline for reading a table, normalizing it, and writing it to a file\n",
    "    # this is a required step\n",
    "    table=[\n",
    "        PartialFn(read_table_from_file),\n",
    "        PartialFn(select_table, idx=0),\n",
    "        PartialFn(table_range_select, start_row=3, end_row=2306, end_col=\"BO\"),\n",
    "        NormTableActor(NormTableArgs()),\n",
    "        PartialFn(\n",
    "            matrix_to_relational_table,\n",
    "            drop_cols=list(range(27, 33)) + list(range(55, 60)),\n",
    "            horizontal_props=[\n",
    "                {\"row\": 0, \"col\": (6, 27)},\n",
    "                {\"row\": 1, \"col\": (6, 27)},\n",
    "                {\"row\": 0, \"col\": (34, 55)},\n",
    "                {\"row\": 1, \"col\": (34, 55)},\n",
    "            ],\n",
    "        ),\n",
    "        PartialFn(to_column_based_table, num_header_rows=2),\n",
    "        PartialFn(write_table_to_file, outdir=cwd / \"output\", format=\"csv\"),\n",
    "    ],\n",
    "    # predict semantic types for each column\n",
    "    sem_label=Flow(\n",
    "        source=\"table\",\n",
    "        target=GppSemLabelActor(\n",
    "            GppSemLabelArgs(\n",
    "                # you can try different models here\n",
    "                # DSL\n",
    "                model=\"tum.sm.dsl.dsl_sem_label.DSLSemLabelModel\",\n",
    "                model_args={\n",
    "                    \"model\": \"logistic-regression\",\n",
    "                    \"ontology_factory\": \"tum.dag.get_ontology\",\n",
    "                    \"data_dir\": PROJECT_DIR / \"data/minmod/mos-v3\",\n",
    "                },\n",
    "                data=\"tum.sm.dsl.dsl_sem_label.get_dataset\",\n",
    "                data_args={},\n",
    "                # OpenAI\n",
    "                # model=\"tum.sm.llm.openai_sem_label.OpenAISemLabel\",\n",
    "                # model_args={\n",
    "                #     \"model\": \"gpt-4.1\",\n",
    "                #     \"api_key\": \"YOUR_OPENAI_KEY\",\n",
    "                #     \"max_sampled_rows\": 20,\n",
    "                # },\n",
    "                # data=\"tum.sm.llm.openai_sem_label.get_dataset\",\n",
    "                # data_args={},\n",
    "            )\n",
    "        ),\n",
    "    ),\n",
    "    # if provided, sand_endpoint will be used to upload table and its predicted semantic\n",
    "    # description to SAND for manual curation\n",
    "    sand_endpoint=\"http://localhost:5524\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f27eb3",
   "metadata": {},
   "source": [
    "#### Running the DAG\n",
    "\n",
    "To execute the DAG, use the `dag.process` function. The `input` argument specifies parameters for any actor in the DAG. It is a mapping from actor IDs to their respective parameters. Since an actor can accept multiple parameters, the values in the mapping should be tuples.\n",
    "\n",
    "The `context` argument allows you to define global parameters that can be assigned to any actors by name.\n",
    "\n",
    "To capture the output of the DAG, use the `output` argument, which is a set of actor IDs. The return value of `dag.process` is a dictionary where the keys are the actor IDs specified in the `output` argument, and the values are lists of items. Each item in the list corresponds to a result from an invocation of the actor. The values are always lists because actors can be invoked multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a194c282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-01 12:14:48.799\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtimer\u001b[0m:\u001b[36mwatch_and_report\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mdeserialize: 0.000 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get context: 0.016 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-01 12:14:54.400\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtimer\u001b[0m:\u001b[36mwatch_and_report\u001b[0m:\u001b[36m74\u001b[0m - \u001b[34m\u001b[1mGppSemLabel.predict deserialize: 0.000 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit the semantic model in SAND at this URL: http://localhost:5524/tables/2\n"
     ]
    }
   ],
   "source": [
    "output = dag.process(\n",
    "    input={\"table\": tuple(cwd.glob(\"*.xlsx\"))},\n",
    "    output=set([\"table\", \"sem_model\"]),\n",
    "    context=get_context(cwd),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32267991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39c52c0e83c4fd6b2d4e2f015d1ec87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<pre>\\n00.\\t<span style=\"background: #b7eb8f; color: black; padding: 2px; border-radius: 3px;\">[0]â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output[\"sem_model\"][0].value.print(env=\"notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
